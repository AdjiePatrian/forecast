Beginning AutoGluon training... Time limit = 180s
AutoGluon will save models to 'D:\Kerja\TensaiTech\prob-forecast\AutogluonModels\ag-20251023_115900'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.12.2
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          20
GPU Count:          0
Memory Avail:       2.44 GB / 15.71 GB (15.5%)
Disk Space Avail:   89.45 GB / 239.46 GB (37.4%)
===================================================

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': WQL,
 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': '-ZeroShot'},
                                  'model_path': 'amazon/chronos-t5-tiny'}]},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 180,
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 71 rows, 1 time series. Median time series length is 71 (min=71, max=71). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 18:59:06
Models that will be trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Training timeseries model Chronos-ZeroShot[amazon__chronos-t5-tiny]. Training for up to 174.0s of the 174.0s of remaining time.
Beginning AutoGluon training... Time limit = 180s
AutoGluon will save models to 'D:\Kerja\TensaiTech\prob-forecast\AutogluonModels\ag-20251023_115913'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.12.2
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          20
GPU Count:          0
Memory Avail:       2.44 GB / 15.71 GB (15.5%)
Disk Space Avail:   89.45 GB / 239.46 GB (37.4%)
===================================================

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': WQL,
 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': '-ZeroShot'},
                                  'model_path': 'amazon/chronos-t5-tiny'}]},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 180,
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 71 rows, 1 time series. Median time series length is 71 (min=71, max=71). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 18:59:13
Models that will be trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Training timeseries model Chronos-ZeroShot[amazon__chronos-t5-tiny]. Training for up to 180.0s of the 180.0s of remaining time.
Beginning AutoGluon training... Time limit = 180s
AutoGluon will save models to 'D:\Kerja\TensaiTech\prob-forecast\AutogluonModels\ag-20251023_115914'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.12.2
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          20
GPU Count:          0
Memory Avail:       2.43 GB / 15.71 GB (15.5%)
Disk Space Avail:   89.45 GB / 239.46 GB (37.4%)
===================================================

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': WQL,
 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': '-ZeroShot'},
                                  'model_path': 'amazon/chronos-t5-tiny'}]},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 180,
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 71 rows, 1 time series. Median time series length is 71 (min=71, max=71). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 18:59:14
Models that will be trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Training timeseries model Chronos-ZeroShot[amazon__chronos-t5-tiny]. Training for up to 179.9s of the 179.9s of remaining time.
Beginning AutoGluon training... Time limit = 180s
AutoGluon will save models to 'D:\Kerja\TensaiTech\prob-forecast\AutogluonModels\ag-20251023_115915'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.12.2
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          20
GPU Count:          0
Memory Avail:       2.43 GB / 15.71 GB (15.5%)
Disk Space Avail:   89.45 GB / 239.46 GB (37.4%)
===================================================

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': WQL,
 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': '-ZeroShot'},
                                  'model_path': 'amazon/chronos-t5-tiny'}]},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 180,
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 71 rows, 1 time series. Median time series length is 71 (min=71, max=71). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 18:59:15
Models that will be trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Training timeseries model Chronos-ZeroShot[amazon__chronos-t5-tiny]. Training for up to 180.0s of the 180.0s of remaining time.
	-0.6166       = Validation score (-WQL)
	8.15    s     = Training runtime
	-0.6249       = Validation score (-WQL)
	-0.5680       = Validation score (-WQL)
	-0.5898       = Validation score (-WQL)
	4.57    s     = Validation (prediction) runtime
	0.09    s     = Training runtime
	1.44    s     = Training runtime
	0.05    s     = Training runtime
	3.96    s     = Validation (prediction) runtime
	4.55    s     = Validation (prediction) runtime
	4.57    s     = Validation (prediction) runtime
Training complete. Models trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Total runtime: 12.77 s
Best model: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Training complete. Models trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Best model score: -0.6166
Training complete. Models trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Total runtime: 4.03 s
Training complete. Models trained: ['Chronos-ZeroShot[amazon__chronos-t5-tiny]']
Total runtime: 6.04 s
Best model: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Total runtime: 4.69 s
Best model: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Best model score: -0.5898
Best model: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Best model score: -0.5680
Best model score: -0.6249
Model not specified in predict, will default to the model with the best validation score: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Model not specified in predict, will default to the model with the best validation score: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Model not specified in predict, will default to the model with the best validation score: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Model not specified in predict, will default to the model with the best validation score: Chronos-ZeroShot[amazon__chronos-t5-tiny]
Model Chronos-ZeroShot[amazon__chronos-t5-tiny] failed to predict with the following exception:
Traceback (most recent call last):
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\trainer.py", line 1080, in get_model_pred_dict
    model_pred_dict[model_name] = self._predict_model(
                                  ^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\trainer.py", line 1009, in _predict_model
    return model.predict(model_inputs, known_covariates=known_covariates)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\abstract\abstract_timeseries_model.py", line 608, in predict
    predictions = self._predict(data=data, known_covariates=known_covariates, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\multi_window\multi_window_model.py", line 199, in _predict
    return self.most_recent_model.predict(data, known_covariates=known_covariates, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\abstract\abstract_timeseries_model.py", line 608, in predict
    predictions = self._predict(data=data, known_covariates=known_covariates, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\chronos\model.py", line 637, in _predict
    self.model_pipeline.model.eval()
    ^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\chronos\model.py", line 240, in model_pipeline
    self.load_model_pipeline()  # load model pipeline to device memory
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\chronos\model.py", line 295, in load_model_pipeline
    pipeline = BaseChronosPipeline.from_pretrained(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\chronos\pipeline\base.py", line 160, in from_pretrained
    return class_.from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\autogluon\timeseries\models\chronos\pipeline\chronos.py", line 540, in from_pretrained
    inner_model = AutoModelForSeq2SeqLM.from_pretrained(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\transformers\modeling_utils.py", line 262, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\transformers\modeling_utils.py", line 4397, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\transformers\modeling_utils.py", line 3162, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "D:\Kerja\TensaiTech\prob-forecast\forecast_env\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

